{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import string\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import jieba\n",
    "import wordcloud\n",
    "from collections import Counter\n",
    "def load_stopword(stop_word_file):\n",
    "    #stop_word_file = \"F:\\\\Desktop\\\\NLP_聊天\\\\stopwords.txt\"\n",
    "    stop_word = open(stop_word_file,encoding=\"utf-8\").read().split('\\n')\n",
    "    return stop_word\n",
    "def get_time(timestamp):\n",
    "    return datetime.fromtimestamp(timestamp)\n",
    "stop_word = load_stopword(\"D:\\\\Desktop\\\\wechat_dig\\\\stopwords.txt\")\n",
    "def remove_word(all_seg_word,stop_word=stop_word):\n",
    "    remove_str = string.punctuation + string.ascii_letters + string.digits + string.whitespace\n",
    "    new_seg_word = []\n",
    "    if stop_word is not None:\n",
    "        all_seg_word = [_ for _ in all_seg_word if _ not in stop_word]\n",
    "    for word in all_seg_word:\n",
    "        if word in [\"我\",\"你\",\"他\",\"她\",\"的\",\"了\",\"不是\", \"就是\", \"这么\", \"怎么\", \"这个\", \"不能\", \"什么\", \"没有\",\"emoji\",\"。\",\"…\",\"，\",\"\\t\",\"\\n\"]:\n",
    "            continue\n",
    "        elif word in list(\"是也去吗吧不\"):\n",
    "            continue\n",
    "        elif word in [\"可以\",\"我们\",\"你们\",\"觉得\",\"他们\",\"流泪\",\"捂脸\",\"一个\",\"飞吻\",\"微笑\",\"难过\",\"发呆\",\"咒骂\",\"尴尬\",\"冷汗\",\"大哭\",\"再见\",\"害羞\",\"尴尬\",\"冷汗\",\"奸笑\",\"可怜\",\"一下\",\"所以\",\"还是\",\n",
    "                     \"那个\",\"现在\",\"然后\",\"可能\",\"知道\",\"大家\",\"自己\",\"但是\",\"真的\",\"流汗\",\"还有\",\"应该\",'一条',\"感觉\"]:\n",
    "            continue\n",
    "        elif \"哈\" in word:\n",
    "            continue\n",
    "        elif word in remove_str:\n",
    "            continue\n",
    "        elif not set(word).difference(set(remove_str)):\n",
    "            continue\n",
    "        new_seg_word.append(word.strip())\n",
    "    return new_seg_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "message_odir = \"D:\\\\Desktop\\\\微信导出\\\\关爱博士成长㍿_3127835014@chatroom\"\n",
    "\n",
    "message_path = message_odir + \"\\\\js\\\\message.js\"\n",
    "data = {}\n",
    "message = open(message_path,'r',encoding='utf-8').read()\n",
    "exec(message.replace('var ',''))\n",
    "\n",
    "# chartroom ID\n",
    "gID = data[\"owner\"]['user']\n",
    "gname = data[\"owner\"]['name']\n",
    "# For chatroom\n",
    "# get all user ID and its name\n",
    "members = data[\"member\"]\n",
    "mid2username = {mid: members[mid]['name'] for mid in members}\n",
    "mid2username.pop(gID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Member id to user name\n",
    "mid2username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_messages_df = pd.DataFrame.from_records(data['message'])\n",
    "\n",
    "\n",
    "all_messages_df.loc[:,'fromWho'] = [mid2username.get(record,'碎碎念达人')\n",
    "                                    for record in all_messages_df.loc[:,\"m_nsRealChatUsr\"]]\n",
    "all_messages_df.loc[:,'datetime'] = [get_time(record)\n",
    "                                     for record in all_messages_df.loc[:,\"m_uiCreateTime\"]]\n",
    "\n",
    "all_messages_df= all_messages_df.loc[:,[\"fromWho\",\"datetime\",\"m_nsContent\"]]\n",
    "all_messages_df = all_messages_df.set_index(\"datetime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid2username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of message (each one)\n",
    "from collections import Counter\n",
    "Counter(mid2username.get(_['m_nsRealChatUsr'],'碎碎念达人')\n",
    "        for _ in data['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "for sid in set(all_messages_df.loc[:,\"fromWho\"]):\n",
    "    sub_df = all_messages_df.loc[all_messages_df.loc[:,'fromWho'] == sid,:]\n",
    "    sub_data = sub_df.resample('M').count()\n",
    "    fig.add_scatter(x=sub_data.index,\n",
    "                    y= sub_data.loc[:,'m_nsContent'],\n",
    "                    name=sid)\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fig2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = all_messages_df.resample('Q').sum()\n",
    "count_data = all_messages_df.resample('Q').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/21 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\liaoth\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.591 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:46<00:00,  2.22s/it]\n"
     ]
    }
   ],
   "source": [
    "ys = []\n",
    "count_num=[]\n",
    "for t,row in tqdm(text_data.iterrows(),total=text_data.shape[0]):\n",
    "    thistext = row[\"m_nsContent\"]\n",
    "    seg_list = jieba.lcut(str(thistext))\n",
    "    filtered_seg = remove_word(seg_list)\n",
    "    w = wordcloud.WordCloud(collocations=False)\n",
    "    w.generate(' '.join(filtered_seg))\n",
    "    count_dict = w.words_\n",
    "    ys.append(';'.join([_[0] for _ in sorted(count_dict.items(),\n",
    "                     key=lambda x:x[1],\n",
    "                     reverse=True)\n",
    "                       ][:5]\n",
    "                      )\n",
    "             )\n",
    "    count_num.append(count_data.loc[t,\"m_nsContent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_scatter(x=text_data.index,\n",
    "                y=count_num,\n",
    "                text=ys,\n",
    "                mode='markers+lines+text',\n",
    "               textposition='top center')\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wordcloud 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_seg_word = jieba.lcut(' '.join(all_messages_df.loc[:,'m_nsContent']))\n",
    "filtered_seg_word = remove_word(total_seg_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x2421b139a58>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wordcloud\n",
    "txt = ' '.join(filtered_seg_word)\n",
    "w = wordcloud.WordCloud(font_path = 'msyh.ttc' , #使用微软雅黑字体\n",
    "                        width = 2000, \n",
    "                        height = 1400, \n",
    "                        background_color = 'white',\n",
    "                        collocations=False,\n",
    "                        colormap ='cividis',\n",
    "                       max_words =500) \n",
    "w.generate(txt)\n",
    "w.to_file(message_odir + '\\\\total.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wordcloud 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_text_data = all_messages_df.resample('Y').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = []\n",
    "count_num=[]\n",
    "for t,row in tqdm(year_text_data.iterrows(),\n",
    "                  total=year_text_data.shape[0]):\n",
    "    thistext = row[\"m_nsContent\"]\n",
    "    seg_list = jieba.lcut(str(thistext))\n",
    "    filtered_seg = remove_word(seg_list)\n",
    "    w = wordcloud.WordCloud(font_path = 'msyh.ttc' ,#使用微软雅黑字体\n",
    "                            width = 2000, \n",
    "                            height = 1400, \n",
    "                            max_words =300,\n",
    "                            background_color = 'white',\n",
    "                            colormap ='cividis',\n",
    "                           collocations=False) \n",
    "    w.generate(' '.join(filtered_seg))\n",
    "    os.makedirs(message_odir +'\\\\年度热词',exist_ok=True)\n",
    "    w.to_file(message_odir+'\\\\年度热词' + '\\\\%s.png' % str(t.year))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
